<!DOCTYPE html>
<html lang="en-us"
  dir="ltr">

<head><script src="/thss/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=thss/livereload" data-no-instant defer></script>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width">








    






<link rel="icon" type="image/ico" href="http:/localhost:1313/thss/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http:/localhost:1313/thss/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http:/localhost:1313/thss/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="192x192" href="http:/localhost:1313/thss/android-chrome-192x192.png">
<link rel="apple-touch-icon" sizes="180x180" href="http:/localhost:1313/thss/apple-touch-icon.png">

<meta name="description" content=""/>



<title>
    
    Cho19 - On the Measure of Intelligence | Thesis Research Notes
    
</title>

<link rel="canonical" href="http://localhost:1313/thss/papers/cho19/"/>

<meta property="og:url" content="http://localhost:1313/thss/papers/cho19/">
  <meta property="og:site_name" content="Thesis Research Notes">
  <meta property="og:title" content="Cho19 - On the Measure of Intelligence">
  <meta property="og:description" content="Overview # The main goal of the AI field since inception has been to create systems with human-like intelligence. Chollet argues this goal is unachievable because there hasn’t been a clear definition of intelligence, nor a standard way to measure it.
In this paper, he proposes a formal definition of intelligence, and a set of guidelines for how a general AI benchmark should look like. He introduces the Abstraction and Reasoning Corpus.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="papers">
    <meta property="article:published_time" content="2025-05-14T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-05-14T00:00:00+00:00">
    <meta property="article:tag" content="Cho19">
    <meta property="article:tag" content="Intelligence">
    <meta property="article:tag" content="ARC-AGI">







<link rel="stylesheet" href="/thss/assets/combined.min.51e60333317bc21d435cd8b1e083282384b6283d25b128fe0b2e2dba06f30264.css" media="all">











    




</head>







<body class="light">

  <div class="content">
    <header>
      

<div class="header">

    

    

    <div class="header-menu">
        

        
        

        <p class="small ">
            <a href="/thss" >
                /home
            </a>
        </p>
        

        <p class="small ">
            <a href="/thss/papers" >
                /papers
            </a>
        </p>
        
        
    </div>

    

</div>
    </header>

    <main class="main">
      







<div >
  <article>
    <header class="single-intro-container">
        
        <h1 class="single-title">Cho19 - On the Measure of Intelligence</h1>
    
        <p class="single-readtime">
          <time datetime="2025-05-14T00:00:00&#43;00:00">May 14, 2025</time>
        </p>
    </header>
      <aside class="toc">
        <p><strong>Table of contents</strong></p>
        <nav id="TableOfContents">
  <ul>
    <li><a href="#overview">Overview</a></li>
    <li><a href="#1-context-and-history">1 Context and History</a>
      <ul>
        <li><a href="#11-need-for-an-actionable-definition-and-measure-of-intelligence">1.1 Need for an actionable definition and measure of intelligence</a></li>
        <li><a href="#12-defining-intelligence-two-divergent-visions">1.2 Defining intelligence: two divergent visions</a></li>
        <li><a href="#13-ai-evaluation-from-measuring-skills-to-measuring-broad-abilities">1.3 AI evaluation: from measuring skills to measuring broad abilities</a></li>
      </ul>
    </li>
    <li><a href="#reference">Reference</a></li>
  </ul>
</nav>
      </aside>
    
    <div class="single-content">
      <hr>
<h2 class="heading" id="overview">
  Overview
  <a class="anchor" href="#overview">#</a>
</h2>
<p>The main goal of the AI field since inception has been to create systems with human-like intelligence.  Chollet argues this goal is unachievable because there hasn&rsquo;t been a clear definition of intelligence, nor a standard way to measure it.</p>
<p>In this paper, he proposes a <strong>formal definition of intelligence</strong>, and a set of guidelines for how a <strong>general AI benchmark</strong> should look like. He introduces the <em><a href="https://github.com/fchollet/ARC-AGI">Abstraction and Reasoning Corpus</a></em>.</p>
<hr>
<h2 class="heading" id="1-context-and-history">
  1 Context and History
  <a class="anchor" href="#1-context-and-history">#</a>
</h2>
<h3 class="heading" id="11-need-for-an-actionable-definition-and-measure-of-intelligence">
  1.1 Need for an actionable definition and measure of intelligence
  <a class="anchor" href="#11-need-for-an-actionable-definition-and-measure-of-intelligence">#</a>
</h3>
<p>We have AI systems that excel at specific tasks, but they still have <strong>limitations</strong> when working with little data and when trying to adapt to novel situations for which they were not trained.</p>
<p>The root of the problem is the <strong>lack of a clear definition of intelligence</strong>, despite the 70 years of AI history. With no clear definition, there is no concrete goal to pursue.</p>
<p>Then, it becomes obvious that we need two things:</p>
<ul>
<li>A clear, actionable, explanatory and <strong>measurable</strong> definition of intelligence.</li>
<li>A <strong>standard</strong> and reliable way to measure it.</li>
</ul>
<p>Chollet points out that the AI community has often neglected efforts to establish (the very much needed) formal definitions and evaluation methods. So, he focuses on identifying the <strong>wrong assumptions</strong> on which the field has been working, and attempts to correct them.</p>
<h3 class="heading" id="12-defining-intelligence-two-divergent-visions">
  1.2 Defining intelligence: two divergent visions
  <a class="anchor" href="#12-defining-intelligence-two-divergent-visions">#</a>
</h3>
<p>He starts analyzing the field&rsquo;s current state. <em>Legg and Hutter (2007)</em> summarized 70 definitions of intelligence into:</p>
<blockquote>
<p>&ldquo;Intelligence measures an agent&rsquo;s ability to achieve goals in a wide range of environments&rdquo;.</p></blockquote>
<p>This definition lets him extract two key components:</p>
<ul>
<li><em>to achieve goals</em>: <strong>task-specific skill</strong></li>
<li><em>in a wide range of environments</em>: capability of <strong>generalization</strong> and adaptation</li>
</ul>
<p>Implicit in the second one, is the fact that an agent must be capable of <strong>learning how to handle new tasks</strong> (<em>skill acquisition</em>) for it to truly be general.</p>
<p>The two components map to the main views of the human mind&rsquo;s nature:</p>
<ul>
<li>One sees the mind as a <strong>static assembly</strong> of special-purpose mechanisms developed through evolution to handle <strong>specific tasks</strong> crucial for survival.</li>
<li>The other one sees the mind is a <strong>flexible</strong> blank slate (<em>Tabula Rasa</em>) capable of turning experience into knowledge and skills.</li>
</ul>
<p>














<figure class=" img-small">

    <div class="img-container" style="--w: 1536; --h: 1024;">
        <img loading="lazy" alt="perspectives" src="/thss/images/perspectives.png#small" width="1536" height="1024">
    </div>

    
    <div class="caption-container">
        <figcaption> Two perspectives </figcaption>
    </div>
    
</figure>
</p>
<p>He analyzes these perspectives before formulating his own definition.</p>
<h4 class="heading" id="121-intelligence-as-a-collection-of-task-specific-skills">
  1.2.1 Intelligence as a <em>collection of task-specific skills</em>
  <a class="anchor" href="#121-intelligence-as-a-collection-of-task-specific-skills">#</a>
</h4>
<p>Originated in <a href="https://en.wikipedia.org/wiki/Darwinism">Darwin</a> (1859), this view considers the mind as a collection of special-purpose adaptations developed by humans to <strong>solve specific problems</strong> faced during evolution.</p>
<p>To the AI community, this view served as a basis for their definition of intelligence. They considered it a set of <strong>static</strong>, program-like routines, relying on <strong>logical operators</strong> for problem-solving, and a <strong>database-like memory</strong> for knowledge storage.</p>
<p>It then became popular to believe that the <em>problem of intelligence</em> would be solved if we could better encode human skills into formal rules and knowledge into databases. This resulted in <strong>evaluation protocols based on performance at specific tasks</strong>.</p>
<p>











<figure class="">

    <div class="img-container" style="--w: 7725; --h: 5137;">
        <img loading="lazy" alt="evolution" src="/thss/images/evolution.jpg" width="7725" height="5137">
    </div>

    
    <div class="caption-container">
        <figcaption> The evolutionary perspective </figcaption>
    </div>
    
</figure>
</p>
<p>As pointed out by <em>Hernández-Orallo (2017)</em>, this view resulted in a paradox:</p>
<blockquote>
<p>&ldquo;The AI field became successful in developing artificial systems that could perform very well on specific tasks <strong>without featuring intelligence at all</strong>&rdquo;.</p></blockquote>
<p>This trend persists today.</p>
<h4 class="heading" id="122-intelligence-as-a-general-learning-ability">
  1.2.2 Intelligence as a <em>general learning ability</em>
  <a class="anchor" href="#122-intelligence-as-a-general-learning-ability">#</a>
</h4>
<p>The alternative view states that intelligence lies in the ability to <strong>acquire new skills through learning</strong>. Such an ability could then apply to a wide range of unseen (or even any) problems.</p>
<p>This perspective aligns with the cognitive science view of the mind as a blank slate: a <strong>flexible</strong>, <strong>adaptable</strong>, <strong>highly general</strong> process that transforms experience into knowledge and skills.</p>
<p>Although <strong>this idea of generality through learning was at the core of AI</strong> at first, it wasn&rsquo;t until the 1980s (with the revolution in deep learning) that it gained serious attention. During this peak many researchers began to conceptualize the mind as a <em>randomly initialized neural network</em> that starts blank and derives skills from training data.</p>
<p>We see the world through the lens of the tools we are most familiar with.</p>
<p>











<figure class="">

    <div class="img-container" style="--w: 7526; --h: 5273;">
        <img loading="lazy" alt="blank slate" src="/thss/images/tabula-rasa.jpg" width="7526" height="5273">
    </div>

    
    <div class="caption-container">
        <figcaption> The skill acquisition perspective </figcaption>
    </div>
    
</figure>
</p>
<p>Today, it has become obvious that <strong>both perspectives</strong>, whether a collection of special-purpose programs or a general-purpose Tabula Rasa, <strong>are incorrect</strong>.</p>
<h3 class="heading" id="13-ai-evaluation-from-measuring-skills-to-measuring-broad-abilities">
  1.3 AI evaluation: from measuring skills to measuring broad abilities
  <a class="anchor" href="#13-ai-evaluation-from-measuring-skills-to-measuring-broad-abilities">#</a>
</h3>
<p>To Chollet it is not only concerning the lack of a clear definition, but also the lack of evaluation methods. <strong>None</strong> of the two perspectives has a <strong>formal</strong> approach for <strong>comprehensive evaluation</strong>.</p>
<h4 class="heading" id="131-skill-based-narrow-ai-evaluation">
  1.3.1 Skill-based, narrow AI evaluation
  <a class="anchor" href="#131-skill-based-narrow-ai-evaluation">#</a>
</h4>
<p>Historically, system evaluation has included:</p>
<ul>
<li><em>Human review</em>: Human judges <strong>observe input-output</strong> pairs and <strong>score them</strong>. This method is <strong>expensive</strong>, impossible to automate or scale, and <strong>subjective</strong>.</li>
<li><em>White-box analysis</em>: Systems are <strong>analyzed internally</strong> to check if they operate as intended.</li>
<li><em>Peer confrontation</em>: Systems <strong>compete against each other</strong> to find the best one.</li>
<li><em>Benchmarking</em>: Systems produce <strong>outputs for which <em>test sets</em> have been defined</strong>, and desired outputs are known.</li>
</ul>
<p><strong>Benchmarks</strong> are considered the best tools for evaluation because they are <strong>reproducible</strong>, <strong>fair</strong>, <strong>scalable</strong>, relatively easy to set up, and <strong>flexible</strong> enough to be applicable to a wide range of tasks.</p>
<p>However, they carry a <strong>hidden pitfall</strong>: they may encourage systems to overly optimize for a specific metric or task, <strong>limiting generalization</strong> to others. In AI, the focus on achieving task-specific performance while placing no conditions on <em>how the system achieves it</em> has led to the development of systems that <strong>lack the sort of human-like intelligence</strong> that the field aspires to.</p>
<p>This was interpreted by McCorduck as an <em>AI effect</em>, and noted by Reed as:</p>
<blockquote>
<p>&ldquo;When we know how a machine does something &lsquo;intelligent&rsquo;, it ceases to be regarded as intelligent. If I beat the world&rsquo;s chess champion, I&rsquo;d be regarded as highly bright.&rdquo;</p></blockquote>
<p>This (wrong) interpretation arises from overly anthropocentric assumptions about intelligence.</p>
<p>For <em>humans</em>, excelling at a specific task is considered proof of intelligence because it demonstrates the <strong>implicit general ability one must have had in the first place to learn that task</strong>. Furthermore, it suggests this ability could be extended to other tasks or domains.</p>
<p>For <em>machines</em> <strong>this is not the case</strong>. So the problem comes from confusing the <strong>intelligence process</strong> (the ability to learn many skills) and the <strong>artifact produced</strong> by this process (good results on particular tasks using those skills), given that in humans they are <strong>intertwined</strong>. For machines being good at one task is just that: being good at one task.</p>
<p>














<figure class=" img-small">

    <div class="img-container" style="--w: 1536; --h: 1024;">
        <img loading="lazy" alt="just-that" src="/thss/images/just-that.png#small" width="1536" height="1024">
    </div>

    
    <div class="caption-container">
        <figcaption> Just that </figcaption>
    </div>
    
</figure>
</p>
<p>The <strong>problem</strong> then has not been measuring AI systems by their performance on specific tasks. Rather, the issue has been <strong>interpreting these results as proof of success</strong> towards developing adaptable and autonomous human-like systems.</p>
<p>Chollet decides to <strong>correct <em>how</em> this success is measured</strong>, focusing on aspects the current field problems exhibit: the need of <em>flexibility</em> and <em>robustness</em>. Moreover, it becomes clear to him that we need to <strong>move beyond skill-based evaluation</strong>, to a more profound assessment of systems&rsquo; generalization capabilities.</p>
<h4 class="heading" id="132-the-spectrum-of-generalization-robustness-flexibility-and-generality">
  1.3.2 The spectrum of generalization: robustness, flexibility and generality
  <a class="anchor" href="#132-the-spectrum-of-generalization-robustness-flexibility-and-generality">#</a>
</h4>
<blockquote>
<p>&ldquo;&hellip; bien qu&rsquo;elles fissent plusieurs choses aussi bien, ou peut-être mieux que nous, elles manqueraient infailliblement en quelques autres, par où on découvrirait qu&rsquo;elles n&rsquo;agiraient pas par connaissance, mais seulement par la disposition de leurs organes.&rdquo;</p>
<p>- René Descartes, 1637</p></blockquote>
<p>Chollet <em>informally</em> defines <strong>generalization</strong> as the <strong>ability of an AI system to handle situations or tasks that differ from previously encountered ones</strong>. These <em>previously encountered situations</em> relate themselves with two types of generalization:</p>
<ul>
<li><em>System-centric generalization</em>: Ability of a learning system to handle situations <strong>it</strong> has never seen before. If an engineer fits a machine learning algorithm on a training set of $N$ samples, its generalization capability would refer to the classification error over images not included in the training set, but that are similar to those in it.</li>
<li><em>Developer-aware generalization</em>: Ability of a (learning or static) system to handle situations <strong>neither the system nor its developer</strong> has seen before. On the previous example, this would mean evaluating the algorithm on data completely outside its training and development sets.</li>
</ul>
<p>Additionally, he defines degrees of generalization:</p>
<ul>
<li><em>Absence of generalization</em>: Generalization requires uncertainty—information unknown to the system or developer. Deterministic systems (e.g., compilers, array sorters, deterministic mathematical functions) involve <strong>no uncertainty</strong>, thus <strong>no generalization</strong>.</li>
<li><em>Local generalization</em> or <strong>robustness</strong>: Ability of a system to handle new data points from <strong>a known distribution</strong> for a single task or well-scoped set of tasks, given a sufficiently dense sampling of examples. Simplified: <em>adaptation to <strong>known unknowns within a single task</strong> or well-scoped set of tasks</em>. This form of generalization has dominated the field since the 50s.</li>
<li><em>Broad generalization</em> or <strong>flexibility</strong>: Ability of a system to handle a broad range of tasks and environments <strong>without further human intervention</strong> (developer-aware generalization). Simplified: <em>adaptation to <strong>unknown unknowns across diverse related tasks</strong></em>. Even the most advanced AI systems from today do not belong to this category.</li>
<li><em>Extreme generalization</em> or <strong>generality</strong>: Ability of open-ended systems to handle entirely new <strong>tasks that only share abstract commonalities</strong> with previously encountered situations, applicable to any task and domain within a wide scope. Simplified: <em>adaptation to <strong>unknown unknowns across an unknown range of tasks</strong> and domains</em>.</li>
</ul>
<p>











<figure class="">

    <div class="img-container" style="--w: 5634; --h: 7043;">
        <img loading="lazy" alt="generalization" src="/thss/images/generalization.jpg" width="5634" height="7043">
    </div>

    
    <div class="caption-container">
        <figcaption> The spectrum of generalization </figcaption>
    </div>
    
</figure>
</p>
<p>Chollet refers, in particular, to &ldquo;<em>human-centric extreme generalization</em>&rdquo; as <em>generality</em>, because <strong>humans are the only known systems</strong> that can <strong>display both system-centric</strong> (quick adaptability to  novel situations from little experience) <strong>and developer-aware generalization</strong> (ability of contemporary humans to handle situations that previous ones in history have never encountered).</p>
<p>One additional category could be noted: <em>universal generalization</em> or <strong>universality</strong>, which extends the notion of <em>generality</em> beyond the scope of humans. However, this lies outside the goals of the AI field, and Chollet considers it irrelevant.</p>
<hr>
<h2 class="heading" id="reference">
  Reference
  <a class="anchor" href="#reference">#</a>
</h2>
<ul>
<li><a href="https://arxiv.org/abs/1911.01547">Chollet, F. (2019). On the measure of intelligence. arXiv preprint arXiv:1911.01547</a>.</li>
</ul>

    </div>
  </article>

  

  

  
  

<div class="single-pagination">
    <hr />

    <div class="flexnowrap">

        <div class="single-pagination-prev">
            
            <div class="single-pagination-container-prev">
                <div class="single-pagination-text">←</div>
                <div class="single-pagination-text">
                    <a href="/thss/papers/">
                        Index
                    </a>
                </div>
            </div>
            
        </div>

        <div class="single-pagination-next">
            
        </div>

    </div>

    <hr />
</div>



  

  

  

</div>


    </main>
  </div>

  
  





    




  <footer>
    

    
    





    




    
    <p>Powered by
        <a href="https://gohugo.io/">Hugo</a>
        and
        <a href="https://github.com/tomfran/typo">tomfran/typo</a>
    </p>
    
    
    


  </footer>

  
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css">
<script defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js"></script>

<script defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js"
  onload="renderMathInElement(document.body);"></script>

<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false }
      ]
    });
  });
</script>
  
</body>

<script src="/thss/js/theme-switch.js"></script>
<script defer src="/thss/js/copy-code.js"></script>
</html>
